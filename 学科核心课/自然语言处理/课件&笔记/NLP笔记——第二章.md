# NLP笔记——第二章

## 数据资源概述

**数据资源发展历程**

- 数据资源按机器学习方法分为

  - 概率统计时期数据资源：包括第一代-第三代语料库，主要是构建大型的通用语料库
  - 深度学习数据资源：第四代语料，主要来源于互联网的海量数据

- 第一代（1970–1980年代）

  特征：百万词级，语言学研究导向。代表：Brown语料库、LLC语料库。

  第二代（1980–1990年代）

  特征：千万词级，词典与语言教学导向。代表：COBUILD（用于Collins词典）、Longman语料库。

  第三代（1990–2010年代）

  特征：上亿词级，标准化标注体系，多语种、NLP应用导向。代表：LDC、Penn Treebank、ACL/DCI语料库

  第四代（2010年代起）

  特征：互联网规模语料 + 深度学习

## 统计时代语料资源

### 语料库 corpus

现代的语料库是指存放在计算机里的原始语料文本或经过加工后带有语言学信息标注的语料文本。

语料库的三点特征：

- 语料库中存放的是在实际使用中**真实**出现过的语言材料。
- 语料库是**以计算机为载体**承载语言知识的基础资源，但并不等于语言知识。
- 真实语料需要经过**分析、处理和加工**，才能成为有用的资源。

语料库的作用：

- 支持语言学研究和语言教学研究
- 支持NLP系统的开发

语料库的类型及相关术语

- 按内容构成和目的划分
  - 异质的（heterogeneous）：最简单的语料收集方法，没有事先规定和选材原则。
  - 同质的（homogeneous）
  - 系统的（systematic）：充分考虑语料动态和静态问题、代表性和平衡问题以及语料库规模等问题
  - 专用的（specialized）
- 按语言种类划分
  - 单语的
  - 双语的或多语的
    - 平行语料库：篇章对齐/句子对齐/结构对齐
- 按是否加工处理过（标注）划分
  - 生预料可
  - 熟语料库
    - 具有词性标注
    - 句法结构信息标注（树库）
    - 语义信息标注

- 共时语料库与历时语料库

典型的语料库资源：布朗语料库（Brown Corpus），LLC口语语料库（London-Lund Corpus of Spoken English），朗文语料库（Longman Corpus），宾州（Pennsylvania）大学树库（UPenn Tree Bank）

![image-20251123101504515](C:\Users\29492\AppData\Roaming\Typora\typora-user-images\image-20251123101504515.png)

### 知识库

语言知识库：从大量的实例语料中提炼、抽象、概括出来的系统的语言知识，如电子词典、句法规则库、词法分析库等。

典型的知识库：WordNet，知识图谱，常识知识库。

知识图谱：本质上是一种语义网络。其结点代表实体或者概念，边代表实体/概念之间的各种语义关系；用来描述真实世界中存在的各种实体和概念，及实体、概念之间的关联关系。

## 深度学习时代的数据资源

### 任务数据资源

在神经网络方法（第二范式）时期，各类语言处理任务主要依靠构建专门的任务神经网络模型，并通过有监督学习对模型进行训练以完成对应任务。在这一阶段，所需的数据资源主要用于训练任务模型，因此使用的数据集主要是针对具体任务进行标注的任务数据集。但由于任务参数知识有限，在需要世界知识的任务上往往表现不佳，因此在第二范式时期常常会引入知识图谱、常识图谱等外部资源。

- 文本分类任务数据集
- 情感分析任务数据集
- 机器翻译任务数据集
- 文本摘要任务数据集
- 机器阅读理解任务数据集
- 问答任务数据集

### 预训练数据资源

在预训练语言模型 + 精调（第三范式）时期，模型训练采用“预训练 + 精调”的模式，即由预训练语言模型参数和下游任务参数共同构成。在这一阶段，需要大量的预训练数据对预训练模型进行训练，同时需要少量的标注任务数据对模型的任务参数进行微调。其中，所需的任务标注数据集可复用第二范式的任务数据。

注：第四范式所用数据与第三范式基本相同，区别是第四范式微调不是调任务模型参数，而是微调预训练语言模型。

网页数据（Common Crawl）、书籍、学术资料、维基百科、代码、混合型数据集。

### 预训练微调数据资源

在预训练大语言模型（第五范式）时期，大模型训练采用“预训练 + 后训练（微调）”模式，即先通过预训练方式对大语言模型进行预训练，然后采用微调的方式让模型输出符合人类认知的输出。其中微调阶段又分为**指令微调**和**对齐微调**：指令微调主要让模型按人类的特定习惯给出输出；对齐微调主要是让模型输出的内容符合人类价值观和偏好。

在这一过程中，预训练阶段需要大量的预训练数据对模型进行训练（数据集可用前节介绍的“预训练数据资源”）；微调阶段的指令微调需要用标注的指令微调数据集进行微调，对齐阶段需要对齐数据集进行微调。

- 指令微调数据集：该类数据集是由标注数据集，主要对大语言模型进行符合人类习惯输出的微调训练。一般有人工标注数据集和用模型合成方法生成的数据集。

- 人类对齐数据集：除了指令微调之外，将大语言模型与人类价值观和偏好对齐也非常重要。现有的对齐目标主要聚焦于三个方面：有用性、诚实性和无害性。自针对上述对齐目标数据集一般进行了标注。